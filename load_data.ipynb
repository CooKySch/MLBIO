{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "# label: dict where keys are the outcome classes and the values are the corresponding indices of columns\n",
    "# rev_index: dict where the keys are the indices of columns and the values are the corresponding outcome classes\n",
    "# features: dict where the keys are the features and the values are the indices\n",
    "label, rev_index, features = pkl.load(open('data/feature_index_all.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Label: \", label)\n",
    "print(\"Review Index: \", rev_index)\n",
    "print(\"Features: \", features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# First column is the guide sequence,\n",
    "# the next 3033 columns are the features(2649 MH binary + 384 one-hot encoded features)\n",
    "# and the last 557 columns are the observed outcome(class) frequencies.\n",
    "\n",
    "Lindel_training = pd.read_csv(\"../Data/Lindel_training.txt\", sep='\\t')\n",
    "# column descriptions\n",
    "#Lindel_training.iloc[0] # guide sequences\n",
    "print(Lindel_training.iloc[0, 0])\n",
    "Lindel_training.iloc[0:1, 2651:3034]\n",
    "# Lindel_training.iloc[1:3034] # 3033 binary features [2649 MH binary features + 384 one hot encoded features]\n",
    "# Lindel_training.iloc[3034:] # 557 observed outcome frequencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model weights from  \n",
    "import pickle as pkl\n",
    "model_weights = pkl.load(open('data/Model_weights.pkl','rb'))\n",
    "# print length fopr each layer\n",
    "print(len(model_weights[0]))\n",
    "print(len(model_weights[1]))\n",
    "print(len(model_weights[2]))\n",
    "print(len(model_weights[3]))\n",
    "print(len(model_weights[4]))\n",
    "print(len(model_weights[5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_del = \"data/L1_del.h5\"\n",
    "l1_ins = \"data/L1_ins.h5\"\n",
    "l1_indel = \"data/L1_indel.h5\"\n",
    "\n",
    "l2_del = \"data/L2_del.h5\"\n",
    "l2_ins = \"data/L2_ins.h5\"\n",
    "l2_indel = \"data/L2_indel.h5\"\n",
    "\n",
    "# array with all files\n",
    "files = [l1_indel, l1_del, l1_ins, ] \n",
    "files_l2 = [l2_indel, l2_del, l2_ins]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_l1 = []\n",
    "from tensorflow import keras    \n",
    "for file in files: \n",
    "    model = keras.models.load_model(file)\n",
    "    print(len(model.get_weights()[0]))\n",
    "    print(len(model.get_weights()[1]))\n",
    "    res_l1.append(model.get_weights()[0])\n",
    "    res_l1.append(model.get_weights()[1])\n",
    "\n",
    "# save res_l1 as pickle to data/Model_weights_l1.pkl\n",
    "import pickle as pkl\n",
    "pkl.dump(res_l1, open('data/Model_weights_l1.pkl','wb'))\n",
    "    \n",
    "# do the same for res_l2\n",
    "res_l2 = []\n",
    "for file in files_l2:\n",
    "    model = keras.models.load_model(file)\n",
    "    print(len(model.get_weights()[0]))\n",
    "    print(len(model.get_weights()[1]))\n",
    "    res_l2.append(model.get_weights()[0])\n",
    "    res_l2.append(model.get_weights()[1])\n",
    "\n",
    "# save res_l2 as pickle to data/Model_weights_l2.pkl\n",
    "import pickle as pkl\n",
    "pkl.dump(res_l2, open('data/Model_weights_l2.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â load prerequesites from data/model_prereq.pkl\n",
    "import pickle as pkl\n",
    "\n",
    "prerequesites = pkl.load(open('data/model_prereq.pkl','rb'))\n",
    "\n",
    "print(prerequesites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3591"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load test data text file\n",
    "\n",
    "test_data = pd.read_csv(\"data/Lindel_test.txt\", sep='\\t')\n",
    "len(test_data.iloc[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536\n"
     ]
    }
   ],
   "source": [
    "# load np array with all predictions\n",
    "import numpy as np\n",
    "test_data = np.load(\"data/predictions_del.npy\")\n",
    "print(len(test_data[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 DEL\n",
      "0.00020098929\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [440, 90]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39m# calculate r2 score\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m r2_score\n\u001b[0;32m----> 9\u001b[0m \u001b[39mprint\u001b[39m(r2_score(test_data, mse_l1_del))\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mL2 DEL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[39m# load mse_l2_del.npy\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_regression.py:911\u001b[0m, in \u001b[0;36mr2_score\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, force_finite)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mr2_score\u001b[39m(\n\u001b[1;32m    785\u001b[0m     y_true,\n\u001b[1;32m    786\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m     force_finite\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    791\u001b[0m ):\n\u001b[1;32m    792\u001b[0m     \u001b[39m\"\"\":math:`R^2` (coefficient of determination) regression score function.\u001b[39;00m\n\u001b[1;32m    793\u001b[0m \n\u001b[1;32m    794\u001b[0m \u001b[39m    Best possible score is 1.0 and it can be negative (because the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[39m    -inf\u001b[39;00m\n\u001b[1;32m    910\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 911\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[39m=\u001b[39m _check_reg_targets(\n\u001b[1;32m    912\u001b[0m         y_true, y_pred, multioutput\n\u001b[1;32m    913\u001b[0m     )\n\u001b[1;32m    914\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    916\u001b[0m     \u001b[39mif\u001b[39;00m _num_samples(y_pred) \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_regression.py:100\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_reg_targets\u001b[39m(y_true, y_pred, multioutput, dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     67\u001b[0m     \u001b[39m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \n\u001b[1;32m     69\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[39m        correct keyword.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[1;32m    101\u001b[0m     y_true \u001b[39m=\u001b[39m check_array(y_true, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    102\u001b[0m     y_pred \u001b[39m=\u001b[39m check_array(y_pred, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 397\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[1;32m    400\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [440, 90]"
     ]
    }
   ],
   "source": [
    "print(\"L1 DEL\")\n",
    "# load mse_l1_del.npy\n",
    "mse_l1_del = np.load(\"data/mse_l1_del.npy\")\n",
    "print(mse_l1_del.min())\n",
    "\n",
    "print(\"L2 DEL\")\n",
    "# load mse_l2_del.npy\n",
    "mse_l2_del = np.load(\"data/mse_l2_del.npy\")\n",
    "print(mse_l2_del.min())\n",
    "\n",
    "print(\"L1 INS\")\n",
    "# load mse_l1_ins.npy\n",
    "mse_l1_ins = np.load(\"data/mse_l1_ins.npy\")\n",
    "print(mse_l1_ins.min())\n",
    "\n",
    "print(\"L2 INS\")\n",
    "# load mse_l2_ins.npy\n",
    "mse_l2_ins = np.load(\"data/mse_l2_ins.npy\")\n",
    "print(mse_l2_ins.min())\n",
    "\n",
    "print(\"L1 INDEL\")\n",
    "# load mse_l1_indel.npy\n",
    "mse_l2_ins = np.load(\"data/mse_l1_indel.npy\")\n",
    "print(mse_l2_ins.min())\n",
    "\n",
    "print(\"L2 INDEL\")\n",
    "# load mse_l2_indel.npy\n",
    "mse_l2_ins = np.load(\"data/mse_l2_indel.npy\")\n",
    "print(mse_l2_ins.min())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
